{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0a0938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator , TransformerMixin\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7a8cd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea0f786",
   "metadata": {},
   "outputs": [],
   "source": [
    " data_preprocessed = pd.read_csv('Absenteeism_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163dc984",
   "metadata": {},
   "outputs": [],
   "source": [
    " data_preprocessed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875823eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The approach we will use here is to create two classes/targets, one representing people who have been excessively absent and another which represents people that haven't.\n",
    "\n",
    "#We will take the median value of the absenteeism time in our cell.\n",
    "\n",
    "# by using the median we have implicitly balanced the data set.\n",
    "\n",
    "#Roughly half of the targets are zeros, while the other half ones\n",
    "\n",
    "#if we dont use the median then One of the two classes exclusively thinking it did very well.\n",
    "\n",
    "#Everything below the median would be considered normal- which is number 0\n",
    "\n",
    "#Everything above the median would be excessively absent - which is number 1\n",
    "\n",
    "data_preprocessed['Absenteeism Time in Hours'].median()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb621b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = np.where(data_preprocessed['Absenteeism Time in Hours']> 3,1,0)\n",
    "\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87ba68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocessed['Excessive Absenteeism'] = targets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b47bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocessed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83714bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets.sum()\n",
    "\n",
    "#total of targets is 319 meaning there are 319 number-1 values. \n",
    "# 319/700 people are excessively absent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67de0057",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36a5d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets.sum()/targets.shape[0]\n",
    "\n",
    "#The result is around zero point four six, so around 46 percent of the targets are ones, thus around 54 percent of the targets are zero.\n",
    "\n",
    "#Usually 60 40 split will work equally well for a logistic regression.\n",
    "\n",
    "# However, a 45-55 percent is almost always sufficient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7625402d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_targets = data_preprocessed.drop(['Absenteeism Time in Hours'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697c297b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_targets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc5b1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_targets is data_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95240c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoint to save data\n",
    "data_with_targets = data_with_targets.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e81d8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_targets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8edc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7fca96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping Date column we already have Day of the Week\n",
    "data_with_targets = data_with_targets.drop(['Date'], axis =1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8bb2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_targets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1535d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6824f1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the inputs for our regression\n",
    "\n",
    "data_with_targets.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc451b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "unscaled_inputs = data_with_targets.iloc[:,:-1]\n",
    "unscaled_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fbac56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling function\n",
    "#absenteeism_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c579f423",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomScaler(BaseEstimator,TransformerMixin):\n",
    "    \n",
    "    def __init__(self,columns,copy=True,with_mean=True,with_std=True):\n",
    "        self.scaler = StandardScaler(copy,with_mean,with_std)\n",
    "        self.columns = columns\n",
    "        self.mean_ = None\n",
    "        self.var_ = None\n",
    "        \n",
    "    def fit(self,X, y = None):\n",
    "        self.scaler.fit(X[self.columns], y)\n",
    "        self.mean_ = np.mean(X[self.columns])\n",
    "        self.var_ =np.var(X[self.columns])\n",
    "        \n",
    "    def transform(self,X , y=None, copy=None):\n",
    "        init_col_order = X.columns\n",
    "        X_scaled = pd.DataFrame(self.scaler.transform(X[self.columns]), columns =self.columns)\n",
    "        X_not_scaled = X.loc[:,~X.columns.isin(self.columns)]\n",
    "        return pd.concat([X_not_scaled, X_scaled], axis=1)[init_col_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a62a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "unscaled_inputs.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ace443e",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_scale = ['Transportation Expense', 'Distance to Work', 'Age',\n",
    "       'Daily Work Load Average', 'Body Mass Index', 'Education',\n",
    "       'Children', 'Pets', 'Month Value', 'Day of the Week']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3858c9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Omitting the dummy variables from the Standardization\n",
    "absenteeism_scaler = CustomScaler(columns_to_scale) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20eeaef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "absenteeism_scaler.fit(unscaled_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7581494c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_inputs = absenteeism_scaler.transform(unscaled_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fe98a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1a2d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####This line will calculate the mean and standard deviation of each feature from unscalable inputs\n",
    "\n",
    "#absenteeism_scaler.fit(unscaled_inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76d1499",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform unscaled inputs into Scaled inputs\n",
    "\n",
    "# scaled_inputs = absenteeism_scaler.transform(unscaled_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2f1b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaled_inputs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad9a5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaled_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85e8589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we dont want to over predict our data just incase something happens and our regression model can not handle it.Therefore, we need to add some data aside for testing.\n",
    "# train_test_split(scaled_inputs, targets)\n",
    "\n",
    "#array 1 = a training dataset with inputs = x_train\n",
    "#array 2 = a training dataset with targets =  y_train\n",
    "#array 3 = a test dataset with inputs = x_test\n",
    "#array 4 = a test dataset with targets = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f07413",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(scaled_inputs, targets, train_size = 0.8, random_state =20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ab0e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (x_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e649ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (x_test.shape, y_test.shape)\n",
    "\n",
    "# our 80 - 20 split worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998bd3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELLING\n",
    "\n",
    "reg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddfad80",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e001351",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.score(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf806478",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Manually check the accuracy of the model ######\n",
    "\n",
    "#Accuracy means that x% ( inputs) of the model outputs match the targets\n",
    "# we are trying to predict for the absent hours based on the trained input pattern that we have , Logistic Regression will predict outputs that are close to targets as possible.\n",
    "\n",
    "#So if we want to find the accuracy of a model manually, we should find the outputs and compare them using Predict function\n",
    "\n",
    "model_outputs = reg.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cd3624",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42ad2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c851d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_outputs == y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7c552a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#total number of matching prediction = total number of true as in boolean true = 1\n",
    "\n",
    "np.sum(model_outputs == y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e623e34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_outputs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a281ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Accuracy = Correct predictions/Observations\n",
    "\n",
    "np.sum(model_outputs == y_train)/model_outputs.shape[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e28b4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the intercept and coefficients\n",
    "\n",
    "reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2674b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d973df75",
   "metadata": {},
   "outputs": [],
   "source": [
    "unscaled_inputs.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de1de07",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name = unscaled_inputs.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3fbd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_table = pd.DataFrame(columns=['Feature Name'],data = feature_name)\n",
    "summary_table['Coefficient'] = np.transpose(reg.coef_)\n",
    "\n",
    "summary_table\n",
    "\n",
    "\n",
    "#The further away from zero (coefficient), no matter if positive or negative, the bigger the weight of this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3c0b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_table.index = summary_table.index +1\n",
    "summary_table.loc[0]= ['Intercept', reg.intercept_[0]]\n",
    "summary_table = summary_table.sort_index()\n",
    "\n",
    "summary_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5504d5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A feature is NOT particularly important if\n",
    "# - coefficient is around 0 = whatever we multiply with 0 will equal to 0 \n",
    "# - odds_ratio is around 1 = if odd_ratio is 1 = no change\n",
    "\n",
    "\n",
    "summary_table['Odds_ratio'] = np.exp(summary_table.Coefficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394136a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_table\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2a6e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_table.sort_values('Odds_ratio', ascending = False)\n",
    "\n",
    "\n",
    "#Odds_ratio of 'Daily Work Load Average','Distance to Work','Day of the Week', is nearly 1 , hence this variable will remain unchanged. We need to consider dropping it as it is useless for our predection model\n",
    "\n",
    "#From the coefficients, it seems that whenever a person has stated reason 1 or in particular it could be any reason, we have a much higher chance of getting excessive absence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f844f14d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
